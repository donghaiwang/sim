import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# åŠ å…¥æ¨¡å‹æ‰€åœ¨å­ç›®å½•
import sys
sys.path.append('./cornet')  # ğŸ‘ˆ åŠ å…¥å­æ–‡ä»¶å¤¹è·¯å¾„
from cornet_z import CORnet_Z  # ğŸ‘ˆ ä»å­æ¨¡å—ä¸­å¯¼å…¥æ¨¡å‹

# ----------- åŠ è½½æ¨¡å‹å¹¶æ³¨å†Œä¸­é—´å±‚ hook ----------
model = CORnet_Z()
model.eval()

activations = {}

def get_hook(name):
    def hook(model, input, output):
        activations[name] = output.detach().cpu()
    return hook

# æ³¨å†Œ hook åˆ°æ¯ä¸€å±‚
model[0].output.register_forward_hook(get_hook('V1'))
model[1].output.register_forward_hook(get_hook('V2'))
model[2].output.register_forward_hook(get_hook('V4'))
model[3].output.register_forward_hook(get_hook('IT'))

# ---------- å›¾åƒé¢„å¤„ç† ----------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# è½½å…¥å¹¶é¢„å¤„ç†å›¾åƒ
image_path = 'your_image.jpg'  # ğŸ‘ˆ æ›¿æ¢ä¸ºä½ çš„å›¾åƒè·¯å¾„
image = Image.open(image_path).convert('RGB')
input_tensor = transform(image).unsqueeze(0)

# ---------- å‰å‘ä¼ æ’­ ----------
with torch.no_grad():
    model(input_tensor)

# ---------- å¯è§†åŒ–ä¸­é—´æ¿€æ´» ----------
def show_activation(name, act_tensor, num_channels=6):
    act = act_tensor.squeeze(0)[:num_channels]
    fig, axes = plt.subplots(1, num_channels, figsize=(15, 5))
    fig.suptitle(name)
    for i in range(num_channels):
        axes[i].imshow(act[i], cmap='viridis')
        axes[i].axis('off')
    plt.savefig(f'{name}_activations.png')
    plt.close()

for layer_name in ['V1', 'V2', 'V4', 'IT']:
    show_activation(layer_name, activations[layer_name])
