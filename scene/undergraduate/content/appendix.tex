\chapter{é™„å½•ï¼šç³»ç»Ÿæ¨¡å—æºä»£ç }

\subsection*{è‡ªç„¶è¯­è¨€ç†è§£ä¸åœºæ™¯ç”Ÿæˆæ¨¡å—}
\begin{enumerate}
	\item \texttt{retrieve.py}
	\begin{itemize}
		\item è¯¥æ–‡ä»¶æ˜¯ç³»ç»Ÿçš„ä¸»æ–‡ä»¶ï¼Œè´Ÿè´£ä»è‡ªç„¶è¯­è¨€æè¿°ä¸­ç”Ÿæˆåœºæ™¯ä»£ç ã€‚å®ƒé›†æˆäº†è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ£€ç´¢å¢å¼ºæ¨¡å—ï¼Œé€šè¿‡è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç¬¦åˆè¾“å…¥è¯­ä¹‰çš„Scenicåœºæ™¯è„šæœ¬ã€‚
	\end{itemize}
	\begin{verbatim}
		import os
		import setGPU
		import csv
		import pickle
		import re
		from sentence_transformers import SentenceTransformer, models
		from os import path as osp
		from tqdm import tqdm
		import argparse
		from architecture import LLMChat
		from utils import load_file, retrieve_topk, generate_code_snippet, save_scenic_code
		
		
		# no need for faiss currently
		# import faiss
		
		# Argument parsing
		parser = argparse.ArgumentParser(description="Set up configurations for your script.")
		parser.add_argument('--port_ip', type=int, default=2000, help='Port IP address (default: 2000)')
		parser.add_argument('--topk', type=int, default=3, help='Top K value (default: 3) for retrieval')
		parser.add_argument('--model', type=str, default='gpt-4o', help="Model name (default: 'gpt-4o'), also support transformers model")
		parser.add_argument('--use_llm', action='store_true', help='if use llm for generating new snippets')
		args = parser.parse_args()
		
		# Configuration
		port_ip = args.port_ip
		topk = args.topk
		use_llm = args.use_llm
		
		# LLM model initialization
		llm_model = LLMChat(args.model)
		local_path = osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__))))
		extraction_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'extraction.txt'))
		behavior_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'behavior.txt'))
		geometry_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'geometry.txt'))
		spawn_prompt = load_file(osp.join(local_path, 'retrieve', 'prompts', 'spawn.txt'))
		scenario_descriptions = load_file(osp.join(local_path, 'retrieve', 'scenario_descriptions.txt')).split('\n')
		
		# ğŸ”¥ ä¿®æ”¹å¼€å§‹ï¼šæœ¬åœ°åŠ è½½ sentence-t5-large æ¨¡å‹
		model_dir = r"D:\sceneMain\chatScene\models\sentence-t5-large"
		if not os.path.exists(model_dir):
		raise FileNotFoundError(f"æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼š{model_dir}")
		
		required_files = ["config.json", "pytorch_model.bin"]
		for filename in required_files:
		if not os.path.exists(os.path.join(model_dir, filename)):
		raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶: {filename} åœ¨ {model_dir} ä¸­")
		
		word_embedding_model = models.Transformer(model_dir, max_seq_length=512)
		pooling_model = models.Pooling(
		word_embedding_model.get_word_embedding_dimension(),
		pooling_mode='mean'
		)
		encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')
		print("âœ… æˆåŠŸåŠ è½½æœ¬åœ° sentence-t5-large æ¨¡å‹ï¼")
		# ğŸ”¥ ä¿®æ”¹ç»“æŸ
		
		# Load the database
		with open(osp.join(local_path, 'retrieve/database_v1.pkl'), 'rb') as file:
		database = pickle.load(file)
		
		behavior_descriptions = database['behavior']['description']
		geometry_descriptions = database['geometry']['description']
		spawn_descriptions = database['spawn']['description']
		behavior_snippets = database['behavior']['snippet']
		geometry_snippets = database['geometry']['snippet']
		spawn_snippets = database['spawn']['snippet']
		
		behavior_embeddings = encoder.encode(behavior_descriptions, device='cuda', convert_to_tensor=True)
		geometry_embeddings = encoder.encode(geometry_descriptions, device='cuda', convert_to_tensor=True)
		spawn_embeddings = encoder.encode(spawn_descriptions, device='cuda', convert_to_tensor=True)
		
		# This is the head for scenic file, you can modify the carla map or ego model here
		head = '''param map = localPath(f'../maps/{Town}.xodr') 
		param carla_map = Town
		model scenic.simulators.carla.model
		EGO_MODEL = "vehicle.lincoln.mkz_2017"
		'''
		
		log_file_path = osp.join(local_path, 'safebench', 'scenario', 'scenario_data', 'scenic_data', 'dynamic_scenario', 'dynamic_log.csv')
		
		# Write log results
		with open(log_file_path, mode='w', newline='') as file:
		log_writer = csv.writer(file)
		log_writer.writerow(['Scenario', 'AdvObject', 'Behavior Description', 'Behavior Snippet', 'Geometry Description', 'Geometry Snippet', 'Spawn Description', 'Spawn Snippet', 'Success'])
		
		# Process each scenario description
		for q, current_scenario in tqdm(enumerate(scenario_descriptions)):
		messages = [
		{"role": "system", "content": "You are a helpful assistant."},
		{"role": "user", "content": extraction_prompt.format(scenario=current_scenario)},
		]
		
		response = llm_model.generate(messages)
		
		try:
		match = re.search(r"Adversarial Object:(.*?)Behavior:(.*?)Geometry:(.*?)Spawn Position:(.*)", response, re.DOTALL)
		if not match:
		raise ValueError("Failed to extract components from the response")
		
		current_adv_object, current_behavior, current_geometry, current_spawn = [s.strip() for s in match.groups()]
		
		# Retrieve the top K relevant snippets
		top_behavior_descriptions, top_behavior_snippets = retrieve_topk(encoder, topk, behavior_descriptions, behavior_snippets, behavior_embeddings, current_behavior)
		top_geometry_descriptions, top_geometry_snippets = retrieve_topk(encoder, topk, geometry_descriptions, geometry_snippets, geometry_embeddings, current_geometry)
		top_spawn_descriptions, top_spawn_snippets = retrieve_topk(encoder, topk, spawn_descriptions, spawn_snippets, spawn_embeddings, current_spawn)
		
		# Generate code snippets using the LLM
		generated_behavior_code = generate_code_snippet(
		llm_model, behavior_prompt, top_behavior_descriptions, top_behavior_snippets, current_behavior, topk, use_llm
		)
		
		generated_geometry_code = generate_code_snippet(
		llm_model, geometry_prompt, top_geometry_descriptions, top_geometry_snippets, current_geometry, topk, use_llm
		)
		
		generated_spawn_code = generate_code_snippet(
		llm_model, spawn_prompt, top_spawn_descriptions, top_spawn_snippets, current_spawn, topk, use_llm
		)
		
		# Log the results
		log_writer.writerow([current_scenario, current_adv_object, current_behavior, generated_behavior_code, current_geometry, generated_geometry_code, current_spawn, generated_spawn_code, 1])
		
		Town, generated_geometry_code = generated_geometry_code.split('\n', 1)
		scenic_code = '\n'.join([f"'''{current_scenario}'''", Town, head, generated_behavior_code, generated_geometry_code, generated_spawn_code.format(AdvObject=current_adv_object)])
		save_scenic_code(local_path, port_ip, scenic_code, q)
		
		except Exception as e:
		log_writer.writerow([current_scenario, '', '', '', '', '', '', '', 0])
		print(f"Failure for scenario: {current_scenario} - Error: {e}")
		
		
	\end{verbatim}
\end{enumerate}

\subsection*{åœºæ™¯åˆæˆä¸ä»¿çœŸæ¨¡å—}
\begin{enumerate}
	\item \texttt{run\_train\_dynamic.py}
	\begin{itemize}
		\item ä½œç”¨ï¼šç”¨äºåœ¨åŠ¨æ€ç”Ÿæˆçš„åœºæ™¯ä¸Šè®­ç»ƒä»£ç†ã€‚è¯¥æ–‡ä»¶ä½¿ç”¨ \texttt{dynamic\_scenic.yaml} è¿›è¡Œé…ç½®ï¼Œå¹¶è¿è¡Œè®­ç»ƒè¿‡ç¨‹ï¼Œä¼˜åŒ–ä»£ç†çš„è¡Œä¸ºã€‚
	\end{itemize}
	\begin{verbatim}
		import setGPU
		import traceback
		import os
		import os.path as osp
		
		import torch 
		from safebench.util.run_util import load_config
		from safebench.util.torch_util import set_seed, set_torch_variable
		from safebench.carla_runner import CarlaRunner
		from safebench.scenic_runner_dynamic import ScenicRunner
		
		if __name__ == '__main__':
		import argparse
		parser = argparse.ArgumentParser()
		parser.add_argument('--exp_name', type=str, default='exp')
		parser.add_argument('--output_dir', type=str, default='log')
		parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
		
		parser.add_argument('--max_episode_step', type=int, default=300)
		parser.add_argument('--auto_ego', action='store_true')
		parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_scenario', 'train_agent', 'eval'])
		parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
		parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['dynamic_scenic.yaml'])
		parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
		parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
		
		parser.add_argument('--seed', '-s', type=int, default=0)
		parser.add_argument('--threads', type=int, default=4)
		parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
		
		parser.add_argument('--num_scenario', '-ns', type=int, default=1, help='num of scenarios we run in one episode')
		parser.add_argument('--save_video', action='store_true')
		parser.add_argument('--render', type=bool, default=True)
		parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
		parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
		parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
		parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
		args = parser.parse_args()
		args_dict = vars(args)
		
		err_list = []
		for agent_cfg in args.agent_cfg:
		for scenario_cfg in args.scenario_cfg:
		# set global parameters
		set_torch_variable(args.device)
		torch.set_num_threads(args.threads)
		set_seed(args.seed)
		
		# load agent config
		agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
		agent_config = load_config(agent_config_path)
		
		# load scenario config
		scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
		scenario_config = load_config(scenario_config_path)
		
		agent_config['load_dir'] = osp.join(agent_config['load_dir'], 'dynamic_scenario')
		# Check if the directory exists; if not, create it
		if not osp.exists(agent_config['load_dir']):
		os.makedirs(agent_config['load_dir'])        
		
		# main entry with a selected mode
		agent_config.update(args_dict)
		args_dict['output_dir'] = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}", "dynamic_scenario")
		scenario_config.update(args_dict)
		scenario_config['num_scenario'] = 1 ### 'the num_scenario can only be one for scenic'
		runner = ScenicRunner(agent_config, scenario_config)
		
		
		# start running
		runner.run()
		
		for err in err_list:
		print(err[0], err[1], 'failed!')
		print(err[2])
		
		
		
	\end{verbatim}
	
	\item \texttt{dynamic\_scenic.yaml}
	\begin{itemize}
		\item ä½œç”¨ï¼šè¯¥æ–‡ä»¶æ˜¯ä»£ç†çš„é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«äº†ä»£ç†çš„è®­ç»ƒè®¾ç½®ï¼ŒåŒ…æ‹¬å…¶è¡Œä¸ºæ¨¡å‹ã€å¯¹æŠ—æ€§è¡Œä¸ºã€åœºæ™¯å±æ€§ç­‰ã€‚å®ƒä¸å…¶ä»– YAML æ–‡ä»¶ç»“åˆä½¿ç”¨æ¥æŒ‡å®šä»£ç†åœ¨ä¸åŒåœºæ™¯ä¸­çš„è¡Œä¸ºã€‚
	\end{itemize}
	\begin{verbatim}
		policy_type: 'scenic'
		scenario_category: 'scenic'
		
		route_dir: 'safebench/scenario/scenario_data/route'
		scenic_dir: 'safebench/scenario/scenario_data/scenic_data/'
		sample_num: 50
		opt_step: 10
		select_num: 2
		
		method: 'scenic'
		scenario_id: null
		route_id: [0,1,2,3,4,5,6,7]
		
		ego_action_dim: 2
		ego_state_dim: 4
		ego_action_limit: 1.0
		
		
	\end{verbatim}
\end{enumerate}

\subsection*{è¯„ä¼°ä¸å±•ç¤ºæ¨¡å—}
\begin{enumerate}
	\item \texttt{evaluate\_scene\_quality.py}
	\begin{itemize}
		\item è¯¥æ–‡ä»¶è´Ÿè´£å¯¹ç”Ÿæˆçš„åœºæ™¯è¿›è¡Œé‡åŒ–è¯„ä¼°ï¼Œè¾“å‡ºè¯­ä¹‰ä¿çœŸåº¦ã€å¤šæ ·æ€§ä¸é©¾é©¶æ€§èƒ½ç›¸å…³æŒ‡æ ‡ã€‚
	\end{itemize}
	\begin{verbatim}
		import os
		import json
		import numpy as np
		import matplotlib.pyplot as plt
		from sklearn.metrics import pairwise_distances_argmin_min
		import cv2
		
		# æ–‡ä»¶è·¯å¾„
		DESCRIPTION_FILE = 'D:/sceneMain/chatScene/retrieve/scenario_descriptions.txt'
		HISTORY_FILE = 'D:/sceneMain/chatScene/retrieve/scenario_history.txt'
		SCENE_IMAGE_DIR = 'D:/sceneMain/chatScene/outputs/'
		
		# åŠ è½½æœ€æ–°çš„åœºæ™¯æè¿°ï¼ˆåªè¯»å–æ–‡ä»¶çš„ç¬¬ä¸€è¡Œï¼‰
		def load_latest_description(path):
		"""åªè¯»å–æè¿°æ–‡ä»¶ä¸­çš„ç¬¬ä¸€è¡Œ"""
		with open(path, 'r', encoding='utf-8') as f:
		first_line = f.readline().strip()  # è¯»å–ç¬¬ä¸€è¡Œ
		return first_line
		
		# å°†æ–°çš„åœºæ™¯æè¿°è¿½åŠ åˆ°å†å²è®°å½•æ–‡ä»¶
		def append_to_history(new_description, history_path):
		"""å°†æ–°çš„åœºæ™¯æè¿°è¿½åŠ åˆ°å†å²æ–‡ä»¶"""
		with open(history_path, 'a', encoding='utf-8') as f:
		f.write(new_description + '\n')
		
		# è®¡ç®—å›¾åƒç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ç»“æ„ç›¸ä¼¼åº¦ï¼‰
		def calculate_image_similarity(image1, image2):
		"""è®¡ç®—ä¸¤å¼ å›¾åƒä¹‹é—´çš„ç›¸ä¼¼åº¦"""
		gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
		gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
		score, _ = cv2.quality.QualitySSIM_compute(gray1, gray2)
		return score
		
		# è®¡ç®—åœºæ™¯çš„å¤šæ ·æ€§ï¼ˆä½¿ç”¨ç”Ÿæˆå›¾åƒä¹‹é—´çš„è·ç¦»ï¼‰
		def calculate_scene_diversity(image_dir):
		"""è®¡ç®—æ‰€æœ‰å›¾åƒä¹‹é—´çš„å¤šæ ·æ€§"""
		images = []
		for filename in os.listdir(image_dir):
		if filename.endswith('.png'):
		img = cv2.imread(os.path.join(image_dir, filename))
		images.append(img)
		
		# è½¬æ¢ä¸ºæ•°ç»„ï¼ˆæ¯ä¸ªå›¾åƒçš„ç‰¹å¾ï¼‰
		image_features = [np.reshape(img, (-1, 3)) for img in images]
		image_features = np.concatenate(image_features, axis=0)
		
		# è®¡ç®—æ¯å¯¹å›¾åƒçš„æœ€å°è·ç¦»
		distances = pairwise_distances_argmin_min(image_features, image_features)
		avg_distance = np.mean(distances[1])  # å¹³å‡æœ€å°è·ç¦»
		return avg_distance
		
		# è¯„ä¼°åœºæ™¯è´¨é‡ï¼šè¯­ä¹‰ä¸€è‡´æ€§ï¼Œå›¾åƒè´¨é‡ï¼Œå¤šæ ·æ€§
		def evaluate_scene_quality(image_dir):
		"""è¯„ä¼°åœºæ™¯çš„è´¨é‡"""
		
		# è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆå‡è®¾ä¸ºæ‰‹åŠ¨æŒ‡å®šæˆ–ä»å…¶ä»–æ–¹æ³•ä¸­è·å¾—ï¼‰
		semantic_consistency = 0.9  # å‡è®¾çš„å€¼ï¼Œé€šå¸¸éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µè¿›è¡Œè®¡ç®—
		
		# å›¾åƒè´¨é‡ï¼šå‡è®¾ä½¿ç”¨å·²æœ‰çš„å‚è€ƒå›¾åƒè¿›è¡Œè¯„ä¼°ï¼ˆæ­¤å¤„ä¸ºä¸€ä¸ªç¤ºä¾‹ï¼‰
		reference_image = cv2.imread('D:/sceneMain/chatScene/reference_image.png')  # å‚è€ƒå›¾åƒ
		image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]
		avg_image_quality = 0
		for image_file in image_files:
		img = cv2.imread(os.path.join(image_dir, image_file))
		similarity = calculate_image_similarity(reference_image, img)
		avg_image_quality += similarity
		avg_image_quality /= len(image_files)
		
		# å¤šæ ·æ€§
		diversity = calculate_scene_diversity(image_dir)
		
		# æ‰“å°è¯„ä¼°ç»“æœ
		print(f"è¯­ä¹‰ä¸€è‡´æ€§: {semantic_consistency}")
		print(f"å¹³å‡å›¾åƒè´¨é‡: {avg_image_quality}")
		print(f"åœºæ™¯å¤šæ ·æ€§: {diversity}")
		
		return semantic_consistency, avg_image_quality, diversity
		
		# ä¸»å‡½æ•°
		def main():
		# è¯»å–æœ€æ–°çš„åœºæ™¯æè¿°
		latest_description = load_latest_description(DESCRIPTION_FILE)
		
		# å°†æè¿°è¿½åŠ åˆ°å†å²è®°å½•
		append_to_history(latest_description, HISTORY_FILE)
		
		# æ‰“å°æœ€æ–°æè¿°
		print(f"æœ€æ–°çš„åœºæ™¯æè¿°: {latest_description}")
		
		# è¯„ä¼°ç”Ÿæˆçš„åœºæ™¯è´¨é‡
		semantic_consistency, avg_image_quality, diversity = evaluate_scene_quality(SCENE_IMAGE_DIR)
		
		# å¯ä»¥æ ¹æ®éœ€è¦å°†è¯„ä¼°ç»“æœä¿å­˜ä¸ºJSONæˆ–å…¶ä»–æ ¼å¼
		evaluation_results = {
			"semantic_consistency": semantic_consistency,
			"avg_image_quality": avg_image_quality,
			"diversity": diversity
		}
		
		# ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ–‡ä»¶
		with open('D:/sceneMain/chatScene/outputs/evaluation_results.json', 'w') as f:
		json.dump(evaluation_results, f, indent=4)
		
		if __name__ == "__main__":
		main()
		
		
	\end{verbatim}
	
	\item \texttt{run\_eval\_dynamic.py}
	\begin{itemize}
		\item è¯¥æ–‡ä»¶ç”¨äºè¿è¡Œè¯„ä¼°æµç¨‹ï¼Œè°ƒç”¨ \texttt{evaluate\_scene\_quality.py} å¯¹ç”Ÿæˆçš„åœºæ™¯è¿›è¡Œè¯„ä¼°ã€‚
	\end{itemize}
	\begin{verbatim}
		import setGPU
		import traceback
		import os.path as osp
		
		import torch 
		
		from safebench.util.run_util import load_config
		from safebench.util.torch_util import set_seed, set_torch_variable
		from safebench.carla_runner import CarlaRunner
		from safebench.scenic_runner_dynamic import ScenicRunner
		
		if __name__ == '__main__':
		import argparse
		parser = argparse.ArgumentParser()
		parser.add_argument('--exp_name', type=str, default='exp')
		parser.add_argument('--output_dir', type=str, default='log')
		parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
		
		parser.add_argument('--max_episode_step', type=int, default=300)
		parser.add_argument('--auto_ego', action='store_true')
		parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_agent', 'train_scenario', 'eval'])
		parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
		parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['dynamic_scenic.yaml'])
		parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
		parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
		
		parser.add_argument('--seed', '-s', type=int, default=0)
		parser.add_argument('--threads', type=int, default=4)
		parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
		
		parser.add_argument('--num_scenario', '-ns', type=int, default=2, help='num of scenarios we run in one episode')
		parser.add_argument('--save_video', action='store_true')
		parser.add_argument('--render', type=bool, default=True)
		parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
		parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
		parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
		parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
		parser.add_argument('--test_policy', type=str, default='sac')
		parser.add_argument('--test_epoch', type=int, default=None)
		args = parser.parse_args()
		
		err_list = []
		for agent_cfg in args.agent_cfg:
		for scenario_cfg in args.scenario_cfg:
		# set global parameters
		set_torch_variable(args.device)
		torch.set_num_threads(args.threads)
		set_seed(args.seed)
		
		# load agent config
		agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
		agent_config = load_config(agent_config_path)
		agent_config['policy_name'] = args.test_policy
		
		## load the corresponding model ##
		agent_config['load_dir'] = osp.join(agent_config['load_dir'], "dynamic_scenario")
		
		# load scenario config
		scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
		scenario_config = load_config(scenario_config_path)
		
		args.output_dir = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}_epoch{args.test_epoch}")
		args.exp_name =  "dynamic_scenario"
		args_dict = vars(args)
		# main entry with a selected mode
		agent_config.update(args_dict)
		print(agent_config['load_dir'])
		scenario_config.update(args_dict)
		
		scenario_config['num_scenario'] = 1 # 'the num_scenario can only be one for scenic'
		runner = ScenicRunner(agent_config, scenario_config)
		
		# start running
		try:
		runner.run(args.test_epoch)
		except:
		runner.close()
		traceback.print_exc()
		err_list.append([agent_cfg, scenario_cfg, traceback.format_exc()])
		
		for err in err_list:
		print(err[0], err[1], 'failed!')
		print(err[2])
		
		
	\end{verbatim}
\end{enumerate}
\subsection*{å…¶ä»–}
\begin{enumerate}
\item \texttt{run\_train.py}
\begin{verbatim}
	import sys
	print(sys.path)
	
	import setGPU
	import traceback
	import os
	import os.path as osp
	
	import torch 
	from safebench.util.run_util import load_config
	from safebench.util.torch_util import set_seed, set_torch_variable
	from safebench.carla_runner import CarlaRunner
	
	if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--exp_name', type=str, default='exp')
	parser.add_argument('--output_dir', type=str, default='log')
	parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
	
	parser.add_argument('--max_episode_step', type=int, default=300)
	parser.add_argument('--auto_ego', action='store_true')
	parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_scenario', 'train_agent', 'eval'])
	parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
	parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['train_scenario_scenic.yaml'])
	parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
	parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
	
	parser.add_argument('--seed', '-s', type=int, default=0)
	parser.add_argument('--threads', type=int, default=4)
	parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
	
	parser.add_argument('--num_scenario', '-ns', type=int, default=1, help='num of scenarios we run in one episode')
	parser.add_argument('--save_video', action='store_true')
	parser.add_argument('--render', type=bool, default=True)
	parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
	parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
	parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
	parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
	parser.add_argument('--scenario_id', type=int, default=None)
	args = parser.parse_args()
	args_dict = vars(args)
	
	err_list = []
	for agent_cfg in args.agent_cfg:
	for scenario_cfg in args.scenario_cfg:
	# set global parameters
	set_torch_variable(args.device)
	torch.set_num_threads(args.threads)
	set_seed(args.seed)
	
	# load agent config
	agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
	agent_config = load_config(agent_config_path)
	
	# load scenario config
	scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
	scenario_config = load_config(scenario_config_path)
	
	## modification
	if args.scenario_id:
	scenario_config['scenario_id'] = args.scenario_id
	
	agent_config['load_dir'] = osp.join(agent_config['load_dir'], f"scenario_{scenario_config['scenario_id']}")
	# Check if the directory exists; if not, create it
	if not osp.exists(agent_config['load_dir']):
	os.makedirs(agent_config['load_dir'])        
	
	# main entry with a selected mode
	agent_config.update(args_dict)
	args_dict['output_dir'] = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}", f"scenario_{scenario_config['scenario_id']}")
	scenario_config.update(args_dict)
	if scenario_config['policy_type'] == 'scenic':
	from safebench.scenic_runner import ScenicRunner
	scenario_config['num_scenario'] = 1 ### 'the num_scenario can only be one for scenic'
	runner = ScenicRunner(agent_config, scenario_config)
	else:
	runner = CarlaRunner(agent_config, scenario_config)
	
	# start running
	runner.run()
	
	for err in err_list:
	print(err[0], err[1], 'failed!')
	print(err[2])
\end{verbatim}
\item \texttt{run\_eval.py}
\begin{verbatim}
	import setGPU
	import traceback
	import os.path as osp
	
	import torch 
	
	from safebench.util.run_util import load_config
	from safebench.util.torch_util import set_seed, set_torch_variable
	from safebench.carla_runner import CarlaRunner
	
	
	if __name__ == '__main__':
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('--exp_name', type=str, default='exp')
	parser.add_argument('--output_dir', type=str, default='log')
	parser.add_argument('--ROOT_DIR', type=str, default=osp.abspath(osp.dirname(osp.dirname(osp.realpath(__file__)))))
	
	parser.add_argument('--max_episode_step', type=int, default=300)
	parser.add_argument('--auto_ego', action='store_true')
	parser.add_argument('--mode', '-m', type=str, default='eval', choices=['train_agent', 'train_scenario', 'eval'])
	parser.add_argument('--agent_cfg', nargs='*', type=str, default=['adv_scenic.yaml'])
	parser.add_argument('--scenario_cfg', nargs='*', type=str, default=['eval_scenic.yaml'])
	parser.add_argument('--continue_agent_training', '-cat', type=bool, default=False)
	parser.add_argument('--continue_scenario_training', '-cst', type=bool, default=False)
	
	parser.add_argument('--seed', '-s', type=int, default=0)
	parser.add_argument('--threads', type=int, default=4)
	parser.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')   
	
	parser.add_argument('--num_scenario', '-ns', type=int, default=2, help='num of scenarios we run in one episode')
	parser.add_argument('--save_video', action='store_true')
	parser.add_argument('--render', type=bool, default=True)
	parser.add_argument('--frame_skip', '-fs', type=int, default=1, help='skip of frame in each step')
	parser.add_argument('--port', type=int, default=2002, help='port to communicate with carla')
	parser.add_argument('--tm_port', type=int, default=8002, help='traffic manager port')
	parser.add_argument('--fixed_delta_seconds', type=float, default=0.1)
	parser.add_argument('--test_policy', type=str, default='sac')
	parser.add_argument('--route_id', type=int, default=0)
	parser.add_argument('--scenario_id', type=int, default=0)
	parser.add_argument('--test_epoch', type=int, default=None)
	args = parser.parse_args()
	
	err_list = []
	for agent_cfg in args.agent_cfg:
	for scenario_cfg in args.scenario_cfg:
	# set global parameters
	set_torch_variable(args.device)
	torch.set_num_threads(args.threads)
	set_seed(args.seed)
	
	# load agent config
	agent_config_path = osp.join(args.ROOT_DIR, 'safebench/agent/config', agent_cfg)
	agent_config = load_config(agent_config_path)
	agent_config['policy_name'] = args.test_policy
	
	## load the corresponding model ##
	agent_config['load_dir'] = osp.join(agent_config['load_dir'], f'scenario_{args.scenario_id}')
	
	# load scenario config
	scenario_config_path = osp.join(args.ROOT_DIR, 'safebench/scenario/config', scenario_cfg)
	scenario_config = load_config(scenario_config_path)
	scenario_config['scenario_id'] = args.scenario_id
	
	args.output_dir = osp.join('log', 'adv_train', args.mode, agent_config['policy_name'], f"{agent_cfg.split('.')[0]}_epoch{args.test_epoch}", f"{scenario_cfg.split('.')[0]}")
	args.exp_name = 'scenario_' + str(scenario_config['scenario_id'])
	args_dict = vars(args)
	# main entry with a selected mode
	agent_config.update(args_dict)
	print(agent_config['load_dir'])
	scenario_config.update(args_dict)
	if scenario_config['policy_type'] == 'scenic':
	from safebench.scenic_runner import ScenicRunner
	scenario_config['num_scenario'] = 1 # 'the num_scenario can only be one for scenic'
	scenario_config['route_id'] = [args.route_id]
	runner = ScenicRunner(agent_config, scenario_config)
	else:
	## id shift due to the test settings in safebench v1
	scenario_config['route_id'] = args.route_id + 4
	runner = CarlaRunner(agent_config, scenario_config)
	
	# start running
	try:
	runner.run(args.test_epoch)
	except:
	runner.close()
	traceback.print_exc()
	err_list.append([agent_cfg, scenario_cfg, traceback.format_exc()])
	
	for err in err_list:
	print(err[0], err[1], 'failed!')
	print(err[2])
	
\end{verbatim}
\end{enumerate}